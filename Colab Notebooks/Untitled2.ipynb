{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOrh1wVVeRIOZADlIIehPG5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LrWGG0Ugtg9k","executionInfo":{"status":"ok","timestamp":1619240990688,"user_tz":-540,"elapsed":2243,"user":{"displayName":"Yeong Sik Jang","photoUrl":"","userId":"03811478516173906731"}},"outputId":"c5a4df04-e02f-4f0f-d170-7708f1d571eb"},"source":["# 좌표의 정답을 찾는 인공신경망\n","\n","import torch\n","import numpy\n","from sklearn.datasets import make_blobs\n","import matplotlib.pyplot as plt\n","\n","n_dim = 2     #디멘션 2차원\n","x_train, y_train = make_blobs(n_samples=80, n_features=n_dim,           # 학습에 쓰이는 데이터 x_train, 레이블 y_train 즉 y_train에는 x_train의 데이터가 레이블이 0과 1어디인지 적어놓은 데이터다\n","                              centers=[[1,1],[-1,-1],[1,-1],[-1,1]],\n","                              shuffle=True, cluster_std=0.3)\n","x_test, y_test = make_blobs(n_samples=20, n_features=n_dim,             # 위와 마찬가지로 레이블 즉 답지를 적어 놓은 데이터를 말함.\n","                            centers=[[1,1],[-1,-1],[1,-1],[-1,1]],\n","                            shuffle=True, cluster_std=0.3)\n","\n","\n","def label_map(y_, from_, to_):                                          # \n","  y = numpy.copy(y_)\n","  for f in from_:\n","    y[y_ == f] = to_\n","  return y\n","\n","print(x_test)\n","print(y_test)\n","\n","y_train = label_map(y_train, [0,1], 0)      # y_train의 레이블 된 데이터들을 0, 1은 무조건 0으로 2, 3은 1로 다시 y_train 지정\n","y_train = label_map(y_train, [2,3], 1)\n","y_test = label_map(y_test, [0,1], 0)\n","y_test = label_map(y_test, [2,3], 1)\n","\n","print(x_test)\n","print(y_test)\n","\n","\n","def vis_data(x,y = None, c = 'r'):          # 그래프로 보여주려고 하는 함수\n","  if y is None:\n","    y = [None] * len(x)\n","  for x_, y_ in zip(x,y):\n","    if y_ is None:\n","      plt.plot(x_[0], x_[1], '*',markerfacecolor='none', markeredgecolor=c)\n","    else:\n","      plt.plot(x_[0], x_[1], c+'o' if y_ == 0 else c+'+')\n","\n","plt.figure()\n","vis_data(x_train, y_train, c='r')\n","plt.show()\n","\n","x_train = torch.FloatTensor(x_train)        # numpy를 pytorch로 바꿈\n","x_test = torch.FloatTensor(x_test)\n","y_train = torch.FloatTensor(y_train)\n","y_test = torch.FloatTensor(y_test)\n","\n","print(x_test)\n","print(y_test)\n","\n","\n","\n","class NeuralNet(torch.nn.Module):               # 학습모델 생성(신경망모델) (input_size 데이터의 차원)\n","  def __init__(self, input_size, hidden_size):\n","    super(NeuralNet, self).__init__()           # 생성자\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","\n","    self.linear_1 = torch.nn.Linear(self.input_size, self.hidden_size)      # 들어오는 데이터에 선형 변환을 적용(input_size를 입력받아서 hidden_size만큼의 중간층 노드를 만듬) y=Ax+b를 변환한다. 정의\n","    self.relu = torch.nn.ReLU()                                             # 활성화 함수 입력값이 0보다 크면 그대로 출력 0이하면 0 정의\n","    self.linear_2 = torch.nn.Linear(self.hidden_size, 1)                    # \n","    self.sigmoid = torch.nn.Sigmoid()                                       # 일정 값을 기준으로 0인지 1인지구분함으로써 분류하는 방식(0과 1사이의 값을 반환하는 활성화 함수)\n","\n","  def forward(self, input_tensor):              # 순전파\n","    linear1 = self.linear_1(input_tensor)\n","    relu = self.relu(linear1)\n","    linear2 = self.linear_2(relu)\n","    output = self.sigmoid(linear2)\n","    return output\n","\n","model = NeuralNet(2,5)\n","learning_rate = 0.03\n","criterion = torch.nn.BCELoss()\n","epochs = 2000\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n","\n","model.eval()  #평가모드\n","test_loss_before = criterion(model(x_test).squeeze(), y_test)\n","print('Before Training, test loss is {}'.format(test_loss_before.item()))\n","\n","print('벡터 [-1,1]이 레이블 1을 가질 확률은 {}'.format(model(torch.FloatTensor([-1,1])).item()))\n","\n","for epoch in range(epochs):\n","  model.train()  #학습모드\n","  optimizer.zero_grad()                                 # 경사값 0으로 설정\n","  train_output = model(x_train)                         # 훈련데이터 입력\n","  train_loss = criterion(train_output.squeeze(), y_train) # 손실 계산\n","  if epoch % 100 == 0:                                  # 100번마다 오차 주는지 \n","    print('Train loss at {} is {}'.format(epoch, train_loss.item()))\n","  train_loss.backward()                                 # 오차함수를 가중치로 미분하여 오차가 최소가 되는 방향을 구하고       [역전파를 행하는 코드]\n","  optimizer.step()                                      # 그 방향으로 모델을 학습률만큼 이동시킴\n","\n","model.eval()\n","test_loss = criterion(model(x_test).squeeze(), y_test)\n","print('After Training, test loss is {}'.format(test_loss.item()))\n","\n","torch.save(model.state_dict(), './model.pt')\n","print('state_dict format of the model: {}'.format(model.state_dict()))\n","\n","new_model = NeuralNet(2,5)\n","new_model.load_state_dict(torch.load('./model.pt'))\n","new_model.eval()\n","print('벡터 [-1,1]이 레이블 1을 가질 확률은 {}'.format(new_model(torch.FloatTensor([-1,1])).item()))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[[ 0.60094995 -0.9296693 ]\n"," [-1.12622403  1.39785432]\n"," [ 0.97712745  1.2171575 ]\n"," [-1.08782377 -0.7967181 ]\n"," [ 0.86504751  0.55927881]\n"," [ 0.75320411 -1.16772155]\n"," [-0.97345579  0.92873287]\n"," [-1.1301717   0.71545897]\n"," [-1.35616963  1.3143423 ]\n"," [ 1.01549712  0.86869822]\n"," [ 0.70676689 -1.05593439]\n"," [-1.05937388 -0.46689793]\n"," [-0.97315134  0.60252157]\n"," [ 1.11087182 -0.30260987]\n"," [-0.61412106 -0.87862809]\n"," [ 0.97049407  1.42981914]\n"," [-0.81089842 -1.19979988]\n"," [ 0.57459367  0.92232538]\n"," [-0.94521226 -0.16240093]\n"," [ 0.93906143 -0.98855041]]\n","[2 3 0 1 0 2 3 3 3 0 2 1 3 2 1 0 1 0 1 2]\n","[[ 0.60094995 -0.9296693 ]\n"," [-1.12622403  1.39785432]\n"," [ 0.97712745  1.2171575 ]\n"," [-1.08782377 -0.7967181 ]\n"," [ 0.86504751  0.55927881]\n"," [ 0.75320411 -1.16772155]\n"," [-0.97345579  0.92873287]\n"," [-1.1301717   0.71545897]\n"," [-1.35616963  1.3143423 ]\n"," [ 1.01549712  0.86869822]\n"," [ 0.70676689 -1.05593439]\n"," [-1.05937388 -0.46689793]\n"," [-0.97315134  0.60252157]\n"," [ 1.11087182 -0.30260987]\n"," [-0.61412106 -0.87862809]\n"," [ 0.97049407  1.42981914]\n"," [-0.81089842 -1.19979988]\n"," [ 0.57459367  0.92232538]\n"," [-0.94521226 -0.16240093]\n"," [ 0.93906143 -0.98855041]]\n","[1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["tensor([[ 0.6009, -0.9297],\n","        [-1.1262,  1.3979],\n","        [ 0.9771,  1.2172],\n","        [-1.0878, -0.7967],\n","        [ 0.8650,  0.5593],\n","        [ 0.7532, -1.1677],\n","        [-0.9735,  0.9287],\n","        [-1.1302,  0.7155],\n","        [-1.3562,  1.3143],\n","        [ 1.0155,  0.8687],\n","        [ 0.7068, -1.0559],\n","        [-1.0594, -0.4669],\n","        [-0.9732,  0.6025],\n","        [ 1.1109, -0.3026],\n","        [-0.6141, -0.8786],\n","        [ 0.9705,  1.4298],\n","        [-0.8109, -1.1998],\n","        [ 0.5746,  0.9223],\n","        [-0.9452, -0.1624],\n","        [ 0.9391, -0.9886]])\n","tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n","        0., 1.])\n","Before Training, test loss is 0.6875295639038086\n","벡터 [-1,1]이 레이블 1을 가질 확률은 0.483304500579834\n","Train loss at 0 is 0.6867817044258118\n","Train loss at 100 is 0.6528397798538208\n","Train loss at 200 is 0.5928797721862793\n","Train loss at 300 is 0.4917827248573303\n","Train loss at 400 is 0.36840203404426575\n","Train loss at 500 is 0.26221534609794617\n","Train loss at 600 is 0.18586465716362\n","Train loss at 700 is 0.13616855442523956\n","Train loss at 800 is 0.10405709594488144\n","Train loss at 900 is 0.08274228870868683\n","Train loss at 1000 is 0.06806378066539764\n","Train loss at 1100 is 0.057521622627973557\n","Train loss at 1200 is 0.0497254952788353\n","Train loss at 1300 is 0.04378288984298706\n","Train loss at 1400 is 0.039098627865314484\n","Train loss at 1500 is 0.035323191434144974\n","Train loss at 1600 is 0.03222154825925827\n","Train loss at 1700 is 0.029632121324539185\n","Train loss at 1800 is 0.027433037757873535\n","Train loss at 1900 is 0.02554335631430149\n","After Training, test loss is 0.04581637308001518\n","state_dict format of the model: OrderedDict([('linear_1.weight', tensor([[-1.1456, -1.3843],\n","        [ 1.2355,  1.2143],\n","        [-1.5913,  1.5129],\n","        [ 1.0944, -1.0951],\n","        [ 1.2911, -1.3152]])), ('linear_1.bias', tensor([ 0.0935,  0.1117, -0.0803, -0.1458, -0.1415])), ('linear_2.weight', tensor([[-1.6854, -1.6246,  2.1088,  1.3695,  1.7955]])), ('linear_2.bias', tensor([-0.7303]))])\n","벡터 [-1,1]이 레이블 1을 가질 확률은 0.9959273934364319\n"],"name":"stdout"}]}]}