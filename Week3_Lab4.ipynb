{"cells":[{"cell_type":"markdown","metadata":{"id":"dk1W_sk12TRc"},"source":["**AI 노바투스과정**\n","\n","Week 3: 딥러닝 기초 I (2023-01-27)\n","\n","실습 #4: 깊은 신경망 학습에 필요한 기술 익히기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLvN_WS1--lA"},"outputs":[],"source":["# keras 라이브러리 가져오기\n","# df\n","# import keras -> import tensorflow.keras as keras\n","import tensorflow.keras as keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5w9C0Guw_dHh"},"outputs":[],"source":["# MNIST 패션 데이터 로딩하기\n","\n","fashion_mnist = keras.datasets.fashion_mnist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5THzsbWu_oAb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"43faaf9b-6eb7-4d3b-891b-724a2b0f4c7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n"]}],"source":["(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVGIpeMgABS5"},"outputs":[],"source":["# 라벨의 각 숫자값에 해당하는 클래스 명 지정하기\n","\n","class_names=[\"T-shirt/top\",'Trouser','Pullover','Dress',\"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a70Q2VQJ_ziq"},"outputs":[],"source":["# 학습용 데이터를 다시 학습용 데이터와 검증용 데이터 (valdiation set) 으로 분리\n","# 분리와 동시에 정규화\n","\n","X_valid, X_train= X_train_full[:5000]/255.0, X_train_full[5000:]/255.0  # 5000개 까지 validation data, 55000개는 train data\n","y_valid, y_train= y_train_full[:5000], y_train_full[5000:]\n","\n","X_test=X_test/255.0"]},{"cell_type":"markdown","metadata":{"id":"YTYa0jX42-GF"},"source":["## 1. 다양한 활성함수 사용해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKxXMaXDASBx"},"outputs":[],"source":["# keras 의 Sequential API 를 활용하여 신경망 모형의 골격 만들기 \n","# 은닉층이 2개이며 첫번째 은닉층에 뉴런 300개, 두번째 은닉층에 뉴런 100개 인 골격 만들기\n","### 새로운 활성함수 사용해보기 !! \n","\n","model = keras.models.Sequential()  # 모델 초기화\n","\n","model.add(keras.layers.Flatten(input_shape=[28,28])) # 28x28 2차원 이미지의 데이터를 1차원데이터로\n","model.add(keras.layers.Dense(300, activation=\"selu\"))\n","model.add(keras.layers.Dense(100, activation=\"elu\"))\n","model.add(keras.layers.Dense(10,  activation=\"softmax\")) #10개의 class에 대한 확률값\n","\n","# https://keras.io/ko/activations/ "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anR1jTNmCUml","outputId":"2b809201-b27b-46e6-f40e-00f32fba9a5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_1 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 300)               235500    \n","                                                                 \n"," dense_4 (Dense)             (None, 100)               30100     \n","                                                                 \n"," dense_5 (Dense)             (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 266,610\n","Trainable params: 266,610\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"7O7I3dXS3Kfc"},"source":["## 2. 다양한 최적화 방법 사용해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMCuI62aCuuZ"},"outputs":[],"source":["# 모형 컴파일하기 (손실함수, 최적화 방법 지정하기)\n","### 다양한 최적화 방법 사용해보기 !\n","\n","# https://keras.io/ko/optimizers/ \n","\n","#optim = keras.optimizers.SGD(clipvalue=1.0)\n","#optim = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)  # momentum\n","#optim = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)  # NAG\n","#optim = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)  # RMSprop\n","#optim = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)  # Adam\n","#model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","\n","optim = keras.optimizers.Adam(learning_rate=0.001)  # 학습률 지정 가능 \n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optim, metrics=[\"accuracy\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FF8L3GJFhhQ","outputId":"f09a4ae9-e826-41bd-bfeb-3c174a28b7de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1719/1719 [==============================] - 8s 4ms/step - loss: 0.4835 - accuracy: 0.8245 - val_loss: 0.3784 - val_accuracy: 0.8616\n","Epoch 2/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.3777 - accuracy: 0.8614 - val_loss: 0.4014 - val_accuracy: 0.8604\n","Epoch 3/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.3428 - accuracy: 0.8717 - val_loss: 0.4139 - val_accuracy: 0.8464\n","Epoch 4/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.3205 - accuracy: 0.8797 - val_loss: 0.3761 - val_accuracy: 0.8682\n","Epoch 5/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.3007 - accuracy: 0.8872 - val_loss: 0.3494 - val_accuracy: 0.8808\n","Epoch 6/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.2848 - accuracy: 0.8936 - val_loss: 0.3231 - val_accuracy: 0.8872\n","Epoch 7/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.2774 - accuracy: 0.8939 - val_loss: 0.3177 - val_accuracy: 0.8892\n","Epoch 8/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.2629 - accuracy: 0.9009 - val_loss: 0.3613 - val_accuracy: 0.8706\n","Epoch 9/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.2517 - accuracy: 0.9043 - val_loss: 0.3153 - val_accuracy: 0.8870\n","Epoch 10/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.2436 - accuracy: 0.9072 - val_loss: 0.3435 - val_accuracy: 0.8826\n"]}],"source":["#모형 학습하기\n","\n","history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"]},{"cell_type":"markdown","metadata":{"id":"lbtl1xRK3Z8-"},"source":["## 3. Dropout 사용해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E10CARVtg-9u"},"outputs":[],"source":["# Dropout : 의도적으로 노드와 노드 사이의 연결을 랜덤으로 끊고 학습시키는 방법. \n","# 노드와 노드 사이의 연결을 끊어 특정 가중치에 과하게 학습되지 않도록 함. --> 과적합 방지 \n","\n","model = keras.models.Sequential()\n","\n","model.add(keras.layers.Flatten(input_shape=[28,28]))\n","model.add(keras.layers.Dropout(rate=0.2))   # 20%의 확률로 레이어 노드간 연결을 끊음 \n","model.add(keras.layers.Dense(300,activation=\"elu\"))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(100,activation=\"elu\"))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(10,activation=\"softmax\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PR9EcCHohVMU"},"outputs":[],"source":["model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PA3HtNKChPRc","outputId":"2000bf11-ae0c-4f5c-b077-a20ba764d430"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1719/1719 [==============================] - 8s 4ms/step - loss: 0.7670 - accuracy: 0.7282 - val_loss: 0.5129 - val_accuracy: 0.8230\n","Epoch 2/10\n","1719/1719 [==============================] - 9s 5ms/step - loss: 0.5701 - accuracy: 0.7962 - val_loss: 0.4642 - val_accuracy: 0.8378\n","Epoch 3/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.5317 - accuracy: 0.8081 - val_loss: 0.4440 - val_accuracy: 0.8476\n","Epoch 4/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.5070 - accuracy: 0.8169 - val_loss: 0.4242 - val_accuracy: 0.8526\n","Epoch 5/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.4942 - accuracy: 0.8211 - val_loss: 0.4126 - val_accuracy: 0.8556\n","Epoch 6/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.4829 - accuracy: 0.8239 - val_loss: 0.4029 - val_accuracy: 0.8600\n","Epoch 7/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.4741 - accuracy: 0.8281 - val_loss: 0.4026 - val_accuracy: 0.8616\n","Epoch 8/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.4665 - accuracy: 0.8303 - val_loss: 0.3917 - val_accuracy: 0.8642\n","Epoch 9/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.4578 - accuracy: 0.8322 - val_loss: 0.3859 - val_accuracy: 0.8654\n","Epoch 10/10\n","1719/1719 [==============================] - 8s 4ms/step - loss: 0.4555 - accuracy: 0.8341 - val_loss: 0.3809 - val_accuracy: 0.8672\n"]}],"source":["history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"]},{"cell_type":"markdown","metadata":{"id":"cuaY91c93i-H"},"source":["## 4. Batch Normalization 사용해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqp8vvzviz6S"},"outputs":[],"source":["# 배치 정규화 : 배치 단위로 신경망을 학습시키는데, 각 배치 입력 데이터들을 정규화하여 Gradient Descent 학습의 안정성 향상 \n","# 학습 과정에서 Batch마다 평균과 분산을 활용하여 데이터의 분포를 정규화하는 과정. 데이터 종류에 따라 값의 범위는 천차만별이기 때문에, Batch마다 입력값의 범위를 스케일링. \n","\n","model=keras.models.Sequential()\n","\n","model.add(keras.layers.Flatten(input_shape=[28,28]))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Dense(300,activation=\"elu\"))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Dense(100,activation=\"elu\"))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Dense(10,activation=\"softmax\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hun7gfqU44Fw","outputId":"1a1ad141-2915-4e52-9535-e93604cfc389"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_4 (Flatten)         (None, 784)               0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 784)              3136      \n"," ormalization)                                                   \n","                                                                 \n"," dense_12 (Dense)            (None, 300)               235500    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 300)              1200      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_13 (Dense)            (None, 100)               30100     \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 100)              400       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_14 (Dense)            (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 271,346\n","Trainable params: 268,978\n","Non-trainable params: 2,368\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOzNdltYi7f9"},"outputs":[],"source":["model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcK5OV9ii8Br","outputId":"fc19b615-0c28-4f9b-9685-07bbfbda4ffb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1719/1719 [==============================] - 11s 6ms/step - loss: 0.5384 - accuracy: 0.8123 - val_loss: 0.4057 - val_accuracy: 0.8590\n","Epoch 2/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.4186 - accuracy: 0.8517 - val_loss: 0.3763 - val_accuracy: 0.8662\n","Epoch 3/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.3804 - accuracy: 0.8639 - val_loss: 0.3544 - val_accuracy: 0.8780\n","Epoch 4/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.3613 - accuracy: 0.8703 - val_loss: 0.3451 - val_accuracy: 0.8810\n","Epoch 5/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.3403 - accuracy: 0.8778 - val_loss: 0.3400 - val_accuracy: 0.8794\n","Epoch 6/10\n","1719/1719 [==============================] - 11s 6ms/step - loss: 0.3246 - accuracy: 0.8826 - val_loss: 0.3261 - val_accuracy: 0.8834\n","Epoch 7/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.3106 - accuracy: 0.8874 - val_loss: 0.3216 - val_accuracy: 0.8848\n","Epoch 8/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.3001 - accuracy: 0.8898 - val_loss: 0.3119 - val_accuracy: 0.8862\n","Epoch 9/10\n","1719/1719 [==============================] - 11s 6ms/step - loss: 0.2891 - accuracy: 0.8940 - val_loss: 0.3212 - val_accuracy: 0.8868\n","Epoch 10/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.2797 - accuracy: 0.8980 - val_loss: 0.3126 - val_accuracy: 0.8904\n"]}],"source":["history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"]},{"cell_type":"markdown","metadata":{"id":"ofYeNbjB3ypm"},"source":["## 5. L1, L2 규제 사용해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_FZI3nZj35m"},"outputs":[],"source":["# 가중치 규제 (Weight Regularization) : \n","# 최소화 하려는 손실함수에 가중치들의 합을 더해주어, 가중치들의 합도 같이 최소화. 특정 가중치에 과하게 학습되는것을 방지 --> 과적합 방지 \n","# L1 규제 : 가중치들의 절댓값 합 적용 \n","# L2 규제 : 가중치들의 제곱 합 적용 : 규제 강도가 더 강함\n","\n","model = keras.models.Sequential()\n","\n","model.add(keras.layers.Flatten(input_shape=[28,28]))\n","model.add(keras.layers.Dense(300,activation=\"elu\"))\n","model.add(keras.layers.Dense(100,activation=\"elu\", kernel_regularizer=keras.regularizers.l1(0.01)))\n","# model.add(keras.layers.Dense(100,activation=\"elu\", kernel_regularizer=keras.regularizers.l2(0.01)))\n","model.add(keras.layers.Dense(10,activation=\"softmax\"))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0jSBsRQlOWa"},"outputs":[],"source":["model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUJ8oayxlPXr","outputId":"fff77653-ddb4-42c2-cca7-ee44fbdcb762"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 5.6396 - accuracy: 0.7399 - val_loss: 1.2175 - val_accuracy: 0.7520\n","Epoch 2/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 1.0294 - accuracy: 0.7576 - val_loss: 0.8759 - val_accuracy: 0.7828\n","Epoch 3/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.8435 - accuracy: 0.7783 - val_loss: 0.8070 - val_accuracy: 0.7880\n","Epoch 4/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.7584 - accuracy: 0.7934 - val_loss: 0.7126 - val_accuracy: 0.8068\n","Epoch 5/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.7049 - accuracy: 0.8055 - val_loss: 0.6742 - val_accuracy: 0.8186\n","Epoch 6/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.6695 - accuracy: 0.8127 - val_loss: 0.6397 - val_accuracy: 0.8268\n","Epoch 7/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.6436 - accuracy: 0.8175 - val_loss: 0.6582 - val_accuracy: 0.8202\n","Epoch 8/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.6247 - accuracy: 0.8226 - val_loss: 0.6023 - val_accuracy: 0.8314\n","Epoch 9/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.6079 - accuracy: 0.8268 - val_loss: 0.6230 - val_accuracy: 0.8204\n","Epoch 10/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.5959 - accuracy: 0.8290 - val_loss: 0.5986 - val_accuracy: 0.8304\n"]}],"source":["history=model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}